{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_excel('MACDONALDS_FINAL_BALANCED_DATA.xlsx')\n",
        "# Dataset was loaded locally during development.\n",
        "# File upload code removed for clean presentation."
      ],
      "metadata": {
        "id": "Cj7HMxA6h3S3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(5)"
      ],
      "metadata": {
        "id": "k0YDTRcbib0o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.shape)\n",
        "print(df.dtypes)"
      ],
      "metadata": {
        "id": "dvXEL7aJjCmC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "fU143DYu84_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['label'].value_counts()"
      ],
      "metadata": {
        "id": "QA6Ygqx_jY85"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The goal of this project is to classify customer reviews into Positive or Negative sentiments using Natural Language Processing and Machine Learning techniques.\n"
      ],
      "metadata": {
        "id": "BQyB5S1WiRZi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report,confusion_matrix\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "metadata": {
        "id": "VPWTWEQTg0-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf = TfidfVectorizer(\n",
        "    max_features=5000,\n",
        "    ngram_range=(1, 2)\n",
        ")\n",
        "\n",
        "x = tfidf.fit_transform(df['review'])\n",
        "y = df['label']"
      ],
      "metadata": {
        "id": "svgmmSWCmAYg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "max_features=5000\n",
        "\n",
        "Keeps only top 5000 important words\n",
        "\n",
        "Reduces overfitting\n",
        "\n",
        "Improves speed\n",
        "\n",
        "ngram_range=(1,2)\n",
        "\n",
        "(1,1) → single words → good\n",
        "\n",
        "(1,2) → single + two-word phrases → not good"
      ],
      "metadata": {
        "id": "wOEq3_xFFWd_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,\n",
        "                                               random_state=42,stratify=y)"
      ],
      "metadata": {
        "id": "1oLr73oCqlLo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "stratify=y Ensures train and test sets keep the same positive/negative class ratio as the original dataset."
      ],
      "metadata": {
        "id": "qkgxPGpYuFvA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logistic=LogisticRegression(max_iter=1000)\n",
        "logistic.fit(x_train,y_train)"
      ],
      "metadata": {
        "id": "bgu-npMLmKO3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "max_iter=1000 Sets enough iterations for Logistic Regression to fully converge and avoid early stopping errors."
      ],
      "metadata": {
        "id": "ulaiwKCJunNH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=logistic.predict(x_test)"
      ],
      "metadata": {
        "id": "a_xQOC8DhukQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc_logistic=accuracy_score(y_test,y_pred)*100\n",
        "print('Accuracy:',acc_logistic)"
      ],
      "metadata": {
        "id": "rNyZn9uMu5aq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confusion=confusion_matrix(y_test,y_pred)\n",
        "print('Confusion Matrix:',confusion)"
      ],
      "metadata": {
        "id": "k5t1ecndQ7kX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "cm = [[48, 1],\n",
        "      [2, 47]]\n",
        "\n",
        "plt.figure(figsize=(4,3))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion Matrix - TF-IDF + Logistic Regression\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BroVtl21yxr0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "scores=cross_val_score(logistic,x,y,cv=5)\n",
        "print(scores)\n",
        "print('mean accuracy:',scores.mean())"
      ],
      "metadata": {
        "id": "AjrmB5N6GiQg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "used 5-fold cross-validation to check overfitting.\n",
        "The accuracy across all folds was consistently around 98–99%, with very low variance.\n",
        "This indicates that the model generalizes well and is not overfitting"
      ],
      "metadata": {
        "id": "6LWSVSjxGynB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_review(review_text):\n",
        "    review_vector = tfidf.transform([review_text])\n",
        "    prediction = logistic.predict(review_vector)[0]\n",
        "    probability = logistic.predict_proba(review_vector).max()\n",
        "    return prediction, probability"
      ],
      "metadata": {
        "id": "sWdP32ApC0w3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_reviews = [\n",
        "    \"The product quality is excellent and I am very satisfied with the purchase.\",\n",
        "    \"Very poor quality, totally disappointed and not worth the money.\",\n",
        "    \"Delivery was fast and the packaging was good, happy with the service.\",\n",
        "    \"The product is not good and the customer support was very bad.\",\n",
        "    \"Amazing experience, works perfectly and looks premium.\",\n",
        "    \"I expected much better but the item stopped working after two days.\"\n",
        "]"
      ],
      "metadata": {
        "id": "pZh4ZzXF2ufM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for review in test_reviews:\n",
        "  label,prob=predict_review(review)\n",
        "  print('\\nReview:',review)\n",
        "  print('prediction:',label)\n",
        "  print('confidence:',round(prob*100,2),'%')"
      ],
      "metadata": {
        "id": "5Kn-FuuM2JNQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confusing_reviews = [\n",
        "    \"The product looks good but the quality is not great.\",\n",
        "    \"It is okay, not bad but not very impressive either.\",\n",
        "    \"I didn’t expect much, but it’s not terrible.\",\n",
        "    \"Great job, it stopped working on the first day.\",\n",
        "    \"If the price was lower, this would have been a good product.\",\n",
        "    \"Customer support was helpful but the product itself is disappointing.\",\n",
        "    \"It works, nothing special.\",\n",
        "    \"Initially it seemed fine, later it turned out to be a bad decision.\"\n",
        "]"
      ],
      "metadata": {
        "id": "xVb5Zz2_nzel"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for review in confusing_reviews:\n",
        "  label,prob=predict_review(review)\n",
        "  print('\\nReview:',review)\n",
        "  print('prediction:',label)\n",
        "  print('confidence:',round(prob*100,2),'%')"
      ],
      "metadata": {
        "id": "F48wA00knznV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TF-IDF with Logistic Regression did not perform well on confusing reviews because it relies on word frequency rather than sentence meaning. It cannot understand context, sarcasm, or mixed sentiment As a result, the model struggles when sentiment depends on word order or context"
      ],
      "metadata": {
        "id": "p08OaP7T9aq4"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XeVqx7wjDa_i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "We7i3tp7BRaQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uA7tu6YdRRCd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "D1AOzcJG7YrE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pipeline is a high-level API that combines tokenization, model prediction, and output processing into a single step."
      ],
      "metadata": {
        "id": "DAPC1_v_GyiM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Internally, it does ALL of this automatically:\n",
        "\n",
        "Raw text\n",
        "→ Tokenization\n",
        "→ Convert tokens to numbers\n",
        "→ Pass through Transformer model\n",
        "→ Get prediction + confidence\n",
        "\n"
      ],
      "metadata": {
        "id": "pkJCOv6k-Q--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_excel('MACDONALDS_FINAL_BALANCED_DATA.xlsx')"
      ],
      "metadata": {
        "id": "a_cg_PhU7f6R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['review'] = df['review'].astype(str).str.strip()"
      ],
      "metadata": {
        "id": "y-AkD3Cs7m9A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "astype(str)\n",
        "It converts every value in the review column into a string.\n",
        "\n",
        "“It ensures all inputs are strings to avoid inference errors.”"
      ],
      "metadata": {
        "id": "VGEsSbj8-6WY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_model = pipeline(\n",
        "    \"sentiment-analysis\",\n",
        "    model=\"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        ")"
      ],
      "metadata": {
        "id": "lHkcomb270ak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "we loaded a pretrained DistilBERT transformer model that is already fine-tuned to classify text into positive or negative sentiment."
      ],
      "metadata": {
        "id": "KZDwu87IENzE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texts = df['review'].tolist()\n",
        "\n",
        "predictions = sentiment_model(texts)"
      ],
      "metadata": {
        "id": "wGfRH6XY74eD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pipeline requires a Python list, not a Pandas Series. That is why we do tolist() to convert it into a pyhton list"
      ],
      "metadata": {
        "id": "SRQ7dBIA_s2x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['predicted_sentiment'] = [\n",
        "    pred['label'].lower() for pred in predictions]\n",
        "\n",
        "df['confidence_score'] = [\n",
        "    pred['score']*100 for pred in predictions]"
      ],
      "metadata": {
        "id": "Yc7wagSg7-oV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This stores the model’s predicted sentiment and confidence score for each review in the DataFrame."
      ],
      "metadata": {
        "id": "4Pbk7oqSEgYm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[['review', 'predicted_sentiment', 'confidence_score']].head(10)"
      ],
      "metadata": {
        "id": "-H6NWxFh8Jeo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confusing_reviews = [\n",
        "    \"The product looks good but the quality is not great.\",\n",
        "    \"It is okay, not bad but not very impressive either.\",\n",
        "    \"I didn’t expect much, but it’s not terrible.\",\n",
        "    \"Great job, it stopped working on the first day.\",\n",
        "    \"If the price was lower, this would have been a good product.\",\n",
        "    \"Customer support was helpful but the product itself is disappointing.\",\n",
        "    \"It works, nothing special.\",\n",
        "    \"Initially it seemed fine, later it turned out to be a bad decision.\"\n",
        "]"
      ],
      "metadata": {
        "id": "SK1_y037Bv7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = sentiment_model(confusing_reviews)\n",
        "\n",
        "for i in range(len(confusing_reviews)):\n",
        "    review = confusing_reviews[i]\n",
        "    prediction = results[i]['label']\n",
        "    confidence = results[i]['score'] * 100\n",
        "\n",
        "    print(\"Review:\", review)\n",
        "    print(\"Prediction:\", prediction)\n",
        "    print(\"Confidence:\", round(confidence, 2), \"%\")\n",
        "    print(\"-\" * 50)"
      ],
      "metadata": {
        "id": "oh6ra6io8Tja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "--- Model Comparison ---\n",
        "\n",
        "    Model  Performance\n",
        "\n",
        "0  Logistic Regression        96.93\n",
        "\n",
        "1        Random Forest        96.94\n",
        "\n",
        "2           DistilBERT        99.52\n",
        ">>> BEST MODEL: DistilBERT <<<"
      ],
      "metadata": {
        "id": "YsC_ZYPmLbFV"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Isdiqkc3Kyyz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}